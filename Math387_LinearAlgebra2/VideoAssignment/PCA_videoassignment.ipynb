{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad9da25",
   "metadata": {},
   "source": [
    "Trevor McCaffrey, Video Assignment for Math 387 (Linear Algebra II)\n",
    "\n",
    "## Application of Linear Algebra - Principal Component Analysis (PCA)\n",
    "\n",
    "In this notebook, I will explain what PCA is, how we can derive it using linear algebra, and some interesting applications of it to real science data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd1bee",
   "metadata": {},
   "source": [
    "#### The Problem\n",
    "\n",
    "When trying to solve a problem, we often analyze a data set containing information describing the problem, and proceed to see what information we can squeeze out of that data set to answer our problem at hand.\n",
    "\n",
    "This may sometimes be simple. For example, suppose we wish to answer the simple problem of which subjects are boys/girls using a data set consisting of height, weight, and strength (determined, say, by number of push-ups) for each subject.  The easiest and most direct way to do this would be to make a simple 3-D plot of these variables and we will likely see two separate distributions representing that of boys and girls.  This is an efficient way to do this because we are dealing with a low(3)-dimensional space, which is easy for humans to visualize.  \n",
    "\n",
    "A common problem arises when we are faced with a \"real-world\" data set, consisting of many more than just 3 variables.  \n",
    "\n",
    "Suppose instead we had 500,000 500x500 pixel images of galaxies from the Hubble Space Telescope, and we wish determine how these galaxies are different, e.g, through their morphology (elliptical/spiral/irregular) and color.  All of this information (and more) is contained within the HST images.  The problem we are faced with now, however, is that rather than three variables (height, weight, and strength) describing our data, we now have 500x500 = 250,000 individual pixels describing each galaxy.  To **fully capture** how each individual galaxy compares to one another, we would need to examine how each of the 250,000 values in each galaxy image compare, which is too large a task to perform: humans generally can not visualize >3 dimensions usefully, let alone how different objects may correlate throughout a *250,000*-dimensional space!\n",
    "\n",
    "Fortunately for the human race, most high-dimensional data in the real world can be described by a much lower dimensional *representation* of itself, which still contains most of the information from the original high-dimension data set.  This is helpful for revealing physical trends in data.  This is doable because certain values in your data set are generally correlated, and may even be somewhat degenerate.  The dimensions of our new low-dimensional representation then represent *combinations* of our original variables.  For example, height and weight may be combined into a single dimension describing each subject's BMI -- two dimensions are not necessary to describe to describe these properties because we can get most of the information we want from a single combination of these two.   In the case of galaxies, we need not examine each individual pixel; a good portion of the image is just dark sky, and what we really want to do is examine *groups* of pixels as this is what will tell us the morphology of the galaxy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4315d38",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "This is where PCA comes into play.  PCA essentially applies a linear transformation to a data set such that our N-dimensional data set is transformed to D dimensions, where $D<<N$, and still contains close to all the information contained from the original N-dimensional data set.  In the language of statistics, the first axis $\\vec{d}_1$, or \"principal component\", of the D-dimensional space will thus be the one-dimensional projection of our data that maximizes the variance in the data.  The second axis  $\\vec{d}_2$, or second principal component, is the one-dimensional projection containing the second-most variance, subject to the constraint that it be orthogonal to $\\vec{d}_1$.  The third axis would be the projection of the N-dimensional data containing the third-most variance, subject to the constraint that it be orthogonal to the preceding axes.  \n",
    "\n",
    "We can continue this to find the \"direction\" of all D principal components.  In general, $\\vec{d}_i$ is the one-dimensional projection of our N-dimensional data containing the $i^\\mathrm{th}$ most variance, subject to the constraint that it be orthogonal to the axes  $\\vec{d}_1,...,\\vec{d}_{i-1}$.\n",
    "\n",
    "Thus, PCA compresses our data set to lower dimension D, whose orthogonal axes reveal the physical variance in our data set better than any of the individual parameters alone.\n",
    "\n",
    "##### Three Dimensional Example\n",
    "\n",
    "The data shown below come from 3 variables.  However, all of the data points essentially just span a plane, so we can describe where each point is within the sample distribution using just two numbers.  Applying PCA to these data locates the plane that the points span, defining new axes $z_1$ and $z_2$, we see that we retain the data distribution despite reducing the dimensionality:\n",
    "\n",
    "(Use 2D projected plane here)\n",
    "\n",
    "\n",
    "##### Two Dimensional Example\n",
    "\n",
    "In some cases, it may make sense to even apply PCA to 2-dimensional data.  The arrow pointing \"in the direction\" of the slope is where most of the variance is contained, so this would bbe the first principal component.  The second principal component is the vector perpendicular to the first, which describes the \"scatter\" for each data point.  We essentially can learn all we want about a particular data point from the first principal component alone, how far along a trendline the point is.\n",
    "\n",
    "(use simple rotation here)\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85be1744",
   "metadata": {},
   "source": [
    "#### Under the Hood - Derivation of PCA \n",
    "\n",
    "We need an orthonormal set of basis vectors that align with the directions of maximum variance in our data set.  These final basis vectors are the \"principal components\" that come from this analysis.\n",
    "\n",
    "If our data set consists of K observations, each with N different measured variables, we denote the full data set $\\{\\vec{x}_i\\}$, where each $\\vec{x}_i$ is a $K\\times1$ vector containing values of the $i^\\mathrm{th}$ variable.\n",
    "\n",
    "The data set can be represented by a single matrix $X$,\n",
    "\n",
    "$$ X = \\underbrace{\\begin{bmatrix}\n",
    "           \\vec{x}_{1}^T \\\\\n",
    "           \\vec{x}_{2}^T \\\\\n",
    "           \\vdots \\\\\n",
    "           \\vec{x}_{N}^T\n",
    "         \\end{bmatrix}}_{N\\times K}. $$\n",
    "         \n",
    "If we normalize the data, so that each of the K variables has $\\mu_i=0$ and $\\sigma_i^2=1$, then the corresponding covariance matrix $C_X$ is just\n",
    "\n",
    "$$ C_X = \\frac{1}{N-1}X^TX. $$\n",
    "\n",
    "If there existed no correlations between the existing variables in our data, this would just be a diagonal matrix.  Off-diagonal terms arise due to cross-correlations within our data, which we will exploit.\n",
    "\n",
    "We now wish to identify a transformation matrix $R$ which projects $X$ onto its newer lower-dimensional space.  Denoting the projected data $Y$, we have:\n",
    "\n",
    "$$ Y = \\underbrace{X}_{N\\times K}\\underbrace{R}_{K\\times D}, $$ where D is the number of dimensions we wish to visualize our data in.  Thus R consists of D axes, each of which contains information from the N variables we started with.\n",
    "\n",
    "The corresponding covariance of $Y$ is\n",
    "\n",
    "$$ C_Y = R^TX^TXR = R^TC_XR. $$\n",
    "\n",
    "\n",
    "The first column of $R$, $r_1$, is the first principal component; it is normal so that $r_1^Tr_1=1$.  By definition, $r_1$ is the direction of maximum variance in our data set $X$.  To find the direction of $r_1$, we need to minimize $r_1^TC_Xr_1$, subject to the constraint $r_1^Tr_1=1$.  This can be done through the method of Lagrange multipliers:\n",
    "\n",
    "$$ \\phi(r_1,\\lambda_1) = r_1^TC_Xr_1 - \\lambda_1(r_1^Tr_1-1). $$\n",
    "\n",
    "Differentiating with respect to $r_1$ and setting equal to zero, we see that:\n",
    "\n",
    "$$ C_Xr_1 = \\lambda_1r_1. $$\n",
    "\n",
    "And we have our crucial result: **the principal components of $X$ are just the eigenvectors of its covariance matrix $C_X$.**  Finding the corresponding eigenvalues and ordering from greatest to least, we will have all of our ordered principal components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f76ecc5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "---\n",
    "\n",
    "### Application to Astronomy\n",
    "\n",
    "Black holes form when young massive stars collapse under their own gravity and can proceed to strongly influence their host galaxies.  A *supermassive* black hole will begin actively accreting material from its surroundings -- dust, gas, sometimes stars -- and form an \"accretion disk\", which emits enormous amounts of light driven by friction in the disk.  *Quasars* are extreme examples of these phenomena, when the light from the accretion disk is so bright that it completely overwhelms the underlying starlight from their host galaxies.  As a result, galaxies that host quasars appear as single bright blue stars through our telescopes:\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"blackholegraphic.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"3c273.png\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>\n",
    "Shown on the left is an artist's impression of a quasar; there is a supermassive black hole in the center accreting material, which in turn emits large amounts of light.  On the right is an actual optical image of 3C273, the first object ever identified as a quasar (Schmidt 1963); the brightness of the quasar is so high that its entire galaxy appears as a single star (hence the name: \"quasar\" = quasi-stellar galaxy).\n",
    "\n",
    "---\n",
    "\n",
    "To analyze the physics and chemistry occuring in different quasars, we point our telescope at them and take spectra.  The Sloan Digital Sky Survey (https://www.sdss.org) took spectra of over 500,000 quasars.  Shown below is a median UV-Optical spectrum of all quasars found in this survey (Vanden Berk et al. 2001):\n",
    "\n",
    "<img src=\"vb01spec.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Each quasar spectrum consists of a continuum (illustrated by the dashed lines) and emission lines.  The emission lines are significantly broadened due the rapid motion of gas around the central black hole; identifying broadened emission lines in ostensibly bright blue stars is the most efficient way of detecting large numbers of black holes in our universe.\n",
    "\n",
    "Quasar spectra contain a wealth of information, and are key to advancing our understanding of black hole physics.  A typical spectrum contains $\\sim3000$ pixels, each with a recorded flux at a given wavelength.  Thus, each quasar lies in a $\\sim3000$-dimensional \"spectrum space.\"  But it doesn't make sense to compare each individual pixel for all 500,000 quasars -- all we really care about is how the overall shape of the spectrum and strength of emission lines change.  It is currently thought that as low as three properties govern the behavior of quasars: their black hole mass, accretion rate (how fast it \"eats up\" material from its surroundings), and the spin rate of the black hole.  Thus, we should be able to describe the information present in the spectra in as low as 3 numbers, rather than >3000.\n",
    "\n",
    "We can use PCA to reduce the dimensionality of these spectra, and attempt to physically interpret the principal components as components of physical quasar properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d0398",
   "metadata": {},
   "source": [
    "Load in quasar spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db6fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b988758d",
   "metadata": {},
   "source": [
    "Run PCA, determine eigenvectors and eigenvalues of covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d6ccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e587c4e1",
   "metadata": {},
   "source": [
    "\"Reconstruct\" the original spectra by multiplying each eigenvalue by their respective eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194875bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c83c7f95",
   "metadata": {},
   "source": [
    "We see that most of the information is retained, despite reducing the dimensionality of the spectra from 3000 to 5.  Analyzing how 5 numbers, rather than 3000, may vary from object to object is a lot simpler for astronomers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddf568f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd98b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1fe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
